---
title: "[validmind](/reference/validmind.html).ai_powered_test"
sidebar: validmind-reference
toc-depth: 4
toc-expand: 4
---

## call_model[()]{.muted}

<!-- function.qmd.jinja2 - function signature -->

::: {.signature} <span class="signature pdoc-code multiline"> <span class="kw">def</span> <span class="name">call_model</span>( <span class="param"> <span class="n">system_prompt</span><span class="p">:</span> <span class="n">str</span></span>, <span class="param"> <span class="n">user_prompt</span><span class="p">:</span> <span class="n">str</span></span>, <span class="param"> <span class="n">temperature</span><span class="p">:</span> <span class="n">float</span> <span class="o">=</span> <span class="kc">0.0</span></span>, <span class="param"> <span class="n">seed</span><span class="p">:</span> <span class="n">int</span> <span class="o">=</span> <span class="kc">42</span></span>):</span> </span> :::

Call LLM with the given prompts and return the response

## get_explanation[()]{.muted}

<!-- function.qmd.jinja2 - function signature -->

::: {.signature} <span class="signature pdoc-code multiline"> <span class="kw">def</span> <span class="name">get_explanation</span>(<span class="param"><span class="n">response</span><span class="p">:</span> <span class="n">str</span></span>):</span> </span> :::

Get just the explanation from the response string TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> "<some-explanation>"

## get_score[()]{.muted}

<!-- function.qmd.jinja2 - function signature -->

::: {.signature} <span class="signature pdoc-code multiline"> <span class="kw">def</span> <span class="name">get_score</span>(<span class="param"><span class="n">response</span><span class="p">:</span> <span class="n">str</span></span>):</span> </span> :::

Get just the score from the response string TODO: use json response mode instead of this

```
e.g. "Score: 8
```

Explanation: <some-explanation>" -> 8
