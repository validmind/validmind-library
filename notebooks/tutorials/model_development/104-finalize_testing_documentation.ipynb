{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ValidMind for model development — 104 Finalize testing and documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validmind as vm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_'></a>\n",
    "\n",
    "## 4. Finalize testing and documentation\n",
    "\n",
    "In this section we cover how to finalize the testing and documentation of your model by focusing on:\n",
    "\n",
    "1. Using `run_documentation_tests()` to ensure custom test results are included in your documentation\n",
    "2. Viewing and updating the configuration for the entire model documentation template\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_1_'></a>\n",
    "\n",
    "### Use `run_documentation_tests()` to ensure custom test results are included in your documentation\n",
    "\n",
    "After adding test driven blocks to your model documentation, changes should persist and become available every time you call `vm.preview_template()`. However, you need to reload the connection to the ValidMind Platform if you have added test driven blocks when the connection was already established.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "vm.reload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run `preview_template()` and verify that the new confusion matrix test you added is included in the proper section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "vm.preview_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the test ID is now registered in the document you can now run tests for an entire section and all additional custom tests should be loaded without issues. Let's run all tests in the `model_evaluation` section of the documentation. Note that we have been running the sample custom confusion matrix with `normalize=True` to demonstrate the ability to provide custom parameters.\n",
    "\n",
    "In the `Run the model evaluation tests` section above you learned how to assign inputs to individual tests with `run_documentation_tests()`. Assigning parametesr is similar, you only need to provide assign a `params` dictionary to a given test ID, `my_test_provider.ConfusionMatrix` in this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"validmind.model_validation.sklearn.ClassifierPerformance:in_sample\": {\n",
    "        \"inputs\": {\n",
    "            \"dataset\": vm_train_ds,\n",
    "            \"model\": vm_model,\n",
    "        },\n",
    "    },\n",
    "    \"my_test_provider.ConfusionMatrix\": {\n",
    "        \"params\": {\"normalize\": True},\n",
    "    },\n",
    "}\n",
    "results = vm.run_documentation_tests(\n",
    "    section=[\"model_evaluation\"],\n",
    "    inputs={\n",
    "        \"dataset\": vm_test_ds,  # Any test that requires a single dataset will use vm_test_ds\n",
    "        \"model\": vm_model,\n",
    "        \"datasets\": (\n",
    "            vm_train_ds,\n",
    "            vm_test_ds,\n",
    "        ),  # Any test that requires multiple datasets will use vm_train_ds and vm_test_ds\n",
    "    },\n",
    "    config=test_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_2_'></a>\n",
    "\n",
    "### Viewing and updating the configuration for the entire model documentation template\n",
    "\n",
    "The ValidMind Library provides a utility function called `vm.get_test_suite().get_default_config()` that allows you to render the default configuration for the entire documentation template. This configuration will contain all the test IDs and their default parameters. You can then modify this configuration as needed and pass it to `run_documentation_tests()` to run all tests in the documentation template if needed. You also have the option to continue running tests for one section at a time, `get_default_config()` still provides a useful reference for providing default parametes to every test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_test_suite = vm.get_test_suite()\n",
    "config = model_test_suite.get_default_config()\n",
    "print(\"Suite Config: \\n\", json.dumps(config, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_2_1_'></a>\n",
    "\n",
    "#### Update the config\n",
    "\n",
    "Note that the default config does not assign any inputs to a test, this is expected. You can assign inputs to individual tests as needed, depending on the datasets and models you want to pass to individual tests. The `config` dictionary, as a mapping of test IDs to test configurations, allows you to do this.\n",
    "\n",
    "For this particular documentation template (binary classification), the ValidMind Library provides a sample configuration that can be used to populate the entire model documentation using the following inputs as placeholders:\n",
    "\n",
    "- A `raw_dataset` raw dataset\n",
    "- A `train_dataset` training dataset\n",
    "- A `test_dataset` test dataset\n",
    "- A trained `model` instance\n",
    "\n",
    "As part of updating the `config` you will need to ensure the correct `input_id`s are used in the final config passed to `run_documentation_tests()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from validmind.datasets.classification import customer_churn\n",
    "from validmind.utils import preview_test_config\n",
    "\n",
    "test_config = customer_churn.get_demo_test_config()\n",
    "preview_test_config(test_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sample configuration, let's finish populating model documentation by running all tests for the `model_development` section of the documentation. Recall that the training and test datasets in our exercise have the following `input_id` values:\n",
    "\n",
    "- `train_dataset_final` for the training dataset\n",
    "- `test_dataset_final` for the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"validmind.model_validation.ModelMetadata\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\"},\n",
    "    },\n",
    "    \"validmind.data_validation.DatasetSplit\": {\n",
    "        \"inputs\": {\"datasets\": [\"train_dataset_final\", \"test_dataset_final\"]},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PopulationStabilityIndex\": {\n",
    "        \"inputs\": {\n",
    "            \"model\": \"log_reg_model_v1\",\n",
    "            \"datasets\": [\"train_dataset_final\", \"test_dataset_final\"],\n",
    "        },\n",
    "        \"params\": {\"num_bins\": 10, \"mode\": \"fixed\"},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "    },\n",
    "    \"my_test_provider.ConfusionMatrix\": {\n",
    "        \"inputs\": {\"dataset\": \"test_dataset_final\", \"model\": \"log_reg_model_v1\"},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ClassifierPerformance:in_sample\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"train_dataset_final\"}\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ClassifierPerformance:out_of_sample\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"}\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PrecisionRecallCurve\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.ROCCurve\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.TrainingTestDegradation\": {\n",
    "        \"inputs\": {\n",
    "            \"model\": \"log_reg_model_v1\",\n",
    "            \"datasets\": [\"train_dataset_final\", \"test_dataset_final\"],\n",
    "        },\n",
    "        \"params\": {\n",
    "            \"metrics\": [\"accuracy\", \"precision\", \"recall\", \"f1\"],\n",
    "            \"max_threshold\": 0.1,\n",
    "        },\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumAccuracy\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "        \"params\": {\"min_threshold\": 0.7},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumF1Score\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "        \"params\": {\"min_threshold\": 0.5},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.MinimumROCAUCScore\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "        \"params\": {\"min_threshold\": 0.5},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.PermutationFeatureImportance\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.SHAPGlobalImportance\": {\n",
    "        \"inputs\": {\"model\": \"log_reg_model_v1\", \"dataset\": \"test_dataset_final\"},\n",
    "        \"params\": {\"kernel_explainer_samples\": 10},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.WeakspotsDiagnosis\": {\n",
    "        \"inputs\": {\n",
    "            \"model\": \"log_reg_model_v1\",\n",
    "            \"datasets\": [\"train_dataset_final\", \"test_dataset_final\"],\n",
    "        },\n",
    "        \"params\": {\n",
    "            \"thresholds\": {\"accuracy\": 0.75, \"precision\": 0.5, \"recall\": 0.5, \"f1\": 0.7}\n",
    "        },\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.OverfitDiagnosis\": {\n",
    "        \"inputs\": {\n",
    "            \"model\": \"log_reg_model_v1\",\n",
    "            \"datasets\": [\"train_dataset_final\", \"test_dataset_final\"],\n",
    "        },\n",
    "        \"params\": {\"cut_off_percentage\": 4},\n",
    "    },\n",
    "    \"validmind.model_validation.sklearn.RobustnessDiagnosis\": {\n",
    "        \"inputs\": {\n",
    "            \"model\": \"log_reg_model_v1\",\n",
    "            \"datasets\": [\"train_dataset_final\", \"test_dataset_final\"],\n",
    "        },\n",
    "        \"params\": {\n",
    "            \"scaling_factor_std_dev_list\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "            \"accuracy_decay_threshold\": 4,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "full_suite = vm.run_documentation_tests(\n",
    "    section=\"model_development\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc8_'></a>\n",
    "\n",
    "## Where to go from here\n",
    "\n",
    "In this notebook you have learned the end-to-end process to document a model with the ValidMind Library, running through some very common scenarios in a typical model development setting:\n",
    "\n",
    "- Running out-of-the-box tests\n",
    "- Documenting your model by adding evidence to model documentation\n",
    "- Extending the capabilities of the ValidMind Library by implementing custom tests\n",
    "- Ensuring that the documentation is complete by running all tests in the documentation template\n",
    "\n",
    "As a next step, you can explore the following notebooks to get a deeper understanding on how the ValidMind Library allows you generate model documentation for any use case:\n",
    "\n",
    "<a id='toc8_1_'></a>\n",
    "\n",
    "### Use cases\n",
    "\n",
    "- [Application scorecard demo](../code_samples/credit_risk/application_scorecard_demo.ipynb)\n",
    "- [Linear regression documentation demo](../code_samples/regression/quickstart_regression_full_suite.ipynb)\n",
    "- [LLM model documentation demo](../code_samples/nlp_and_llm/foundation_models_integration_demo.ipynb)\n",
    "\n",
    "<a id='toc8_2_'></a>\n",
    "\n",
    "### More how-to guides and code samples\n",
    "\n",
    "- [Explore available tests in detail](../how_to/explore_tests.ipynb)\n",
    "- [In-depth guide for implementing custom tests](../code_samples/custom_tests/implement_custom_tests.ipynb)\n",
    "- [In-depth guide to external test providers](../code_samples/custom_tests/integrate_external_test_providers.ipynb)\n",
    "- [Configuring dataset features](../how_to/configure_dataset_features.ipynb)\n",
    "- [Introduction to unit and composite metrics](../how_to/run_unit_metrics.ipynb)\n",
    "\n",
    "<a id='toc8_3_'></a>\n",
    "\n",
    "### Discover more learning resources\n",
    "\n",
    "All notebook samples can be found in the following directories of the ValidMind Library GitHub repository:\n",
    "\n",
    "- [Code samples](https://github.com/validmind/validmind-library/tree/main/notebooks/code_samples)\n",
    "- [How-to guides](https://github.com/validmind/validmind-library/tree/main/notebooks/how_to)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc9_'></a>\n",
    "\n",
    "## Upgrade ValidMind\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #B5B5B510; color: black; border: 1px solid #083E44; border-left-width: 5px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);border-radius: 5px;\">After installing ValidMind, you’ll want to periodically make sure you are on the latest version to access any new features and other enhancements.</div>\n",
    "\n",
    "Retrieve the information for the currently installed version of ValidMind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the version returned is lower than the version indicated in our [production open-source code](https://github.com/validmind/validmind-library/blob/prod/validmind/__version__.py), restart your notebook and run:\n",
    "\n",
    "```bash\n",
    "%pip install --upgrade validmind\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to restart your kernel after running the upgrade package for changes to be applied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ValidMind Library",
   "language": "python",
   "name": "validmind"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
