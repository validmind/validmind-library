{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ValidMind for model validation — 112 Develop potential challenger models\n",
    "\n",
    "Learn how to use ValidMind for your end-to-end model validation process based on common scenarios with our series of four introductory notebooks. In this second notebook, develop challenger models through a structured comparison process.\n",
    "\n",
    "A *challenger model* is an alternate model that attempt to outperform the champion model, ensuring that the best performing fit-for-purpose model is always considered for deployment. Challenger models also help avoid over-reliance on a single model, and allow testing of new features, algorithms, or data sources without disrupting the production lifecycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "In order to continue on the model validation journey with notebook, you'll need to first have:\n",
    "\n",
    "- [ ] Registered a model within the ValidMind Platform and granted yourself access to the model as a validator\n",
    "- [ ] Installed the ValidMind Library in your local environment, allowing you to access all its features\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #B5B5B510; color: black; border: 1px solid #083E44; border-left-width: 5px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);border-radius: 5px;\"><span style=\"color: #083E44;\"><b>Need help with the above steps?</b></span>\n",
    "<br></br>\n",
    "Refer to the first notebook in this series: <a href=\"111-set_up_validmind.ipynb\" style=\"color: #DE257E;\"><b>111 Set up ValidMind</b></a></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the feature engineered dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating potential challenger models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the ValidMind objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WIP BELOW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7347ccf",
   "metadata": {},
   "source": [
    "### Enable custom context for test descriptions\n",
    "\n",
    "When you run ValidMind tests, test descriptions are automatically generated with LLM using the test results, the test name, and the static test definitions provided in the test’s docstring. While this metadata offers valuable high-level overviews of tests, insights produced by the LLM-based descriptions may not always align with your specific use cases or incorporate organizational policy requirements.\n",
    "\n",
    "Here, we'll include some initial custom use case context, improving the relevancy, insight, and format of the test descriptions returned.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #B5B5B510; color: black; border: 1px solid #083E44; border-left-width: 5px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);border-radius: 5px;\"><span style=\"color: #083E44;\"><b>Want to learn more about setting custom context for LLM-generated test descriptions?</b></span>\n",
    "<br></br>\n",
    "Refer to our extended walkthrough notebook: <a href=\"https://docs.validmind.ai/notebooks/how_to/add_context_to_llm_descriptions.html\" style=\"color: #DE257E;\"><b>Add context to LLM-generated test descriptions\n",
    "</b></a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad6e51",
   "metadata": {},
   "source": [
    "#### Review default LLM-generated descriptions\n",
    "\n",
    "By default, custom context for LLM-generated descriptions is disabled, meaning that the output will not include any additional context.\n",
    "\n",
    "Let's generate an initial test description for the `HighPearsonCorrelation` test for comparison with later iterations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb4450d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighPearsonCorrelation\",\n",
    "    inputs={\n",
    "        \"dataset\": fe_df,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5612ba38",
   "metadata": {},
   "source": [
    "#### Enable use case context\n",
    "\n",
    "To enable custom use case context, set the `VALIDMIND_LLM_DESCRIPTIONS_CONTEXT_ENABLED` environment variable to `1`.\n",
    "\n",
    "This is a global setting that will affect all tests for your linked model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6105468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"VALIDMIND_LLM_DESCRIPTIONS_CONTEXT_ENABLED\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e90ba",
   "metadata": {},
   "source": [
    "Enabling use case context allows you to pass in additional context to the LLM-generated text descriptions within `context`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7fb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "FORMAT FOR THE LLM DESCRIPTIONS: \n",
    "    **<Test Name>** is designed to <begin with a concise overview of what the test does and its primary purpose, \n",
    "    extracted from the test description>.\n",
    "\n",
    "    The test operates by <write a paragraph about the test mechanism, explaining how it works and what it measures. \n",
    "    Include any relevant formulas or methodologies mentioned in the test description.>\n",
    "\n",
    "    The primary advantages of this test include <write a paragraph about the test's strengths and capabilities, \n",
    "    highlighting what makes it particularly useful for specific scenarios.>\n",
    "\n",
    "    Users should be aware that <write a paragraph about the test's limitations and potential risks. \n",
    "    Include both technical limitations and interpretation challenges. \n",
    "    If the test description includes specific signs of high risk, incorporate these here.>\n",
    "\n",
    "    **Key Insights:**\n",
    "\n",
    "    The test results reveal:\n",
    "\n",
    "    - **<insight title>**: <comprehensive description of one aspect of the results>\n",
    "    - **<insight title>**: <comprehensive description of another aspect>\n",
    "    ...\n",
    "\n",
    "    Based on these results, <conclude with a brief paragraph that ties together the test results with the test's \n",
    "    purpose and provides any final recommendations or considerations.>\n",
    "\n",
    "ADDITIONAL INSTRUCTIONS:\n",
    "    Present insights in order from general to specific, with each insight as a single bullet point with bold title.\n",
    "    You are a model validator and the goal is to identify risk and/or suggest room for improvements or recommendations on what Model Developer should do in order to improve outcomes and reduce risk\n",
    "\n",
    "    For each metric in the test results, include in the test overview:\n",
    "    - The metric's purpose and what it measures\n",
    "    - Its mathematical formula\n",
    "    - The range of possible values\n",
    "    - What constitutes good/bad performance\n",
    "    - How to interpret different values\n",
    "\n",
    "    Each insight should progressively cover:\n",
    "    1. Overall scope and distribution\n",
    "    2. Complete breakdown of all elements with specific values\n",
    "    3. Natural groupings and patterns\n",
    "    4. Comparative analysis between datasets/categories\n",
    "    5. Stability and variations\n",
    "    6. Notable relationships or dependencies\n",
    "\n",
    "    Remember:\n",
    "    - Keep all insights at the same level (no sub-bullets or nested structures)\n",
    "    - Make each insight complete and self-contained\n",
    "    - Include specific numerical values and ranges\n",
    "    - Cover all elements in the results comprehensively\n",
    "    - Maintain clear, concise language\n",
    "    - Use only \"- **Title**: Description\" format for insights\n",
    "    - Progress naturally from general to specific observations\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "os.environ[\"VALIDMIND_LLM_DESCRIPTIONS_CONTEXT\"] = context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e38bd2",
   "metadata": {},
   "source": [
    "With the use case context set, generate an updated test description for the `DatasetDescription` test for comparision with default output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adede511",
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighPearsonCorrelation\",\n",
    "    inputs={\n",
    "        \"dataset\": fe_df,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
