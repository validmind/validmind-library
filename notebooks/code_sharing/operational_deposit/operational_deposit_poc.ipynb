{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operational Deposit Model Documentation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "::: {.content-hidden when-format=\"html\"}\n",
    "## Contents    \n",
    "- [About ValidMind](#toc1__)    \n",
    "  - [Before you begin](#toc1_1__)    \n",
    "  - [New to ValidMind?](#toc1_2__)    \n",
    "- [Initialize the ValidMind Library](#toc2__)    \n",
    "  - [Register sample model](#toc2_1__)    \n",
    "  - [Apply documentation template](#toc2_2__)    \n",
    "  - [Get your code snippet](#toc2_3__)    \n",
    "- [Data preparation](#toc3__)    \n",
    "- [ValidMind objects](#toc4__)    \n",
    "- [Data Validation](#toc5__)    \n",
    "  - [Dataset summary](#toc5_1__)    \n",
    "  - [Duplicates](#toc5_2__)    \n",
    "  - [Missing values](#toc5_3__)    \n",
    "  - [Unique rows](#toc5_4__)    \n",
    "  - [High cardinality](#toc5_5__)    \n",
    "  - [Skewness](#toc5_6__)    \n",
    "  - [Zero Values](#toc5_7__)    \n",
    "  - [Descriptive statistics](#toc5_8__)    \n",
    "  - [High pearson correlation](#toc5_9__)    \n",
    "  - [Pearson correlation matrix](#toc5_10__)    \n",
    "- [Segmentation of clients](#toc6__)    \n",
    "  - [Clustering](#toc6_1__)    \n",
    "  - [Prediction](#toc6_2__)    \n",
    "  - [Compare Manual vs predicted](#toc6_3__)    \n",
    "  - [Confusion matrix - test data](#toc6_4__)    \n",
    "  - [Hyper parameter tuning](#toc6_5__)    \n",
    "  - [Cluster performance metrics](#toc6_6__)    \n",
    "  - [No of clusters optimization](#toc6_7__)    \n",
    "- [Operational deposit  model](#toc7__)    \n",
    "  - [Operational deposit model compuation](#toc7_1__)    \n",
    "  - [Prepare VM dataset for the model](#toc7_2__)    \n",
    "  - [VM model](#toc7_3__)    \n",
    "  - [External test provider](#toc7_4__)    \n",
    "  - [Simple custom test](#toc7_5__)    \n",
    "- [Where to go from here](#toc8__)    \n",
    "  - [Use cases](#toc8_1__)    \n",
    "  - [More how-to guides and code samples](#toc8_2__)    \n",
    "  - [Discover more learning resources](#toc8_3__)    \n",
    "- [Upgrade ValidMind](#toc9__)    \n",
    "\n",
    ":::\n",
    "<!-- jn-toc-notebook-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=2\n",
    "\tmaxLevel=4\n",
    "\t/jn-toc-notebook-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc1__'></a>\n",
    "\n",
    "## About ValidMind\n",
    "\n",
    "ValidMind is a suite of tools for managing model risk, including risk associated with AI and statistical models.\n",
    "\n",
    "You use the ValidMind Library to automate documentation and validation tests, and then use the ValidMind Platform to collaborate on model documentation. Together, these products simplify model risk management, facilitate compliance with regulations and institutional standards, and enhance collaboration between yourself and model validators.\n",
    "\n",
    "<a id='toc1_1__'></a>\n",
    "\n",
    "### Before you begin\n",
    "\n",
    "This notebook assumes you have basic familiarity with Python, including an understanding of how functions work. If you are new to Python, you can still run the notebook but we recommend further familiarizing yourself with the language. \n",
    "\n",
    "If you encounter errors due to missing modules in your Python environment, install the modules with `pip install`, and then re-run the notebook. For more help, refer to [Installing Python Modules](https://docs.python.org/3/installing/index.html).\n",
    "\n",
    "<a id='toc1_2__'></a>\n",
    "\n",
    "### New to ValidMind?\n",
    "\n",
    "If you haven't already seen our documentation on the [ValidMind Library](https://docs.validmind.ai/developer/validmind-library.html), we recommend you begin by exploring the available resources in this section. There, you can learn more about documenting models and running tests, as well as find code samples and our Python Library API reference.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #B5B5B510; color: black; border: 1px solid #083E44; border-left-width: 5px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);border-radius: 5px;\"><span style=\"color: #083E44;\"><b>For access to all features available in this notebook, you'll need access to a ValidMind account.</b></span>\n",
    "<br></br>\n",
    "<a href=\"https://docs.validmind.ai/guide/configuration/register-with-validmind.html\" style=\"color: #DE257E;\"><b>Register with ValidMind</b></a></div>\n",
    "\n",
    "![Dataset based test architecture](./dataset_image.png)\n",
    "![Model based test architecture](./model_image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites\n",
    "\n",
    "Let's go ahead and install the `validmind` library if its not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q validmind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"VM_OVERRIDE_METADATA\"] = \"true\"\n",
    "os.environ[\"VALIDMIND_LLM_DESCRIPTIONS_ENABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc2__'></a>\n",
    "\n",
    "## Initialize the ValidMind Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc2_1__'></a>\n",
    "\n",
    "### Register sample model\n",
    "\n",
    "Let's first register a sample model for use with this notebook:\n",
    "\n",
    "1. In a browser, [log in to ValidMind](https://docs.validmind.ai/guide/configuration/log-in-to-validmind.html).\n",
    "\n",
    "2. In the left sidebar, navigate to **Inventory** and click **+ Register Model**.\n",
    "\n",
    "3. Enter the model details and click **Next >** to continue to assignment of model stakeholders. ([Need more help?](https://docs.validmind.ai/guide/model-inventory/register-models-in-inventory.html))\n",
    "\n",
    "   For example, to register a model for use with this notebook, select the following use case: `Credit Risk - Underwriting - Loans`\n",
    "\n",
    "4. Select your own name under the **MODEL OWNER** drop-down.\n",
    "\n",
    "5. Click **Register Model** to add the model to your inventory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc2_2__'></a>\n",
    "\n",
    "### Apply documentation template\n",
    "\n",
    "Once you've registered your model, let's select a documentation template. A template predefines sections for your model documentation and provides a general outline to follow, making the documentation process much easier.\n",
    "\n",
    "1. In the left sidebar that appears for your model, click **Documents** and select **Documentation**.\n",
    "\n",
    "2. Under **[template]{.smallcaps}**, select `Time Series Forecasting`.\n",
    "\n",
    "3. Click **Use Template** to apply the template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc2_3__'></a>\n",
    "\n",
    "### Get your code snippet\n",
    "\n",
    "ValidMind generates a unique _code snippet_ for each registered model to connect with your developer environment. You initialize the ValidMind Library with this code snippet, which ensures that your documentation and tests are uploaded to the correct model when you run the notebook.\n",
    "\n",
    "1. On the left sidebar that appears for your model, select **Getting Started** and click **Copy snippet to clipboard**.\n",
    "2. Next, [load your model identifier credentials from an `.env` file](https://docs.validmind.ai/developer/model-documentation/store-credentials-in-env-file.html) or replace the placeholder with your own code snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your model identifier credentials from an `.env` file\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv .env\n",
    "\n",
    "# Or replace with your code snippet\n",
    "\n",
    "import validmind as vm\n",
    "\n",
    "vm.init(\n",
    "    # api_host=\"...\",\n",
    "    # api_key=\"...\",\n",
    "    # api_secret=\"...\",\n",
    "    # model=\"...\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before learning how to run tests, let's explore the list of all available tests in the ValidMind Library. You can see that the documentation template for this model has references to some of the test IDs listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some data quality assessments by running a few individual tests related to data assessment. You will use the `vm.tests.list_tests()` function introduced above in combination with `vm.tests.list_tags()` and `vm.tests.list_tasks()` to find which prebuilt tests are relevant for data quality assessment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available tags\n",
    "sorted(vm.tests.list_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of available tasks\n",
    "sorted(vm.tests.list_tasks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass `tags` and `tasks` as parameters to the `vm.tests.list_tests()` function to filter the tests based on the tags and task types. For example, to find tests related to tabular data quality for classification models, you can call `list_tests()` like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests(task=\"classification\", tags=[\"tabular_data\", \"data_quality\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc3__'></a>\n",
    "\n",
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv(\"./datasets/odm_data_example/synthetic_data.csv\")\n",
    "print(f\"Columns {list(raw_df.columns)}\")\n",
    "print(f\"Size {list(raw_df.shape)}\")\n",
    "\n",
    "raw_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data validation\n",
    "\n",
    "Now that we have loaded our dataset, we can go ahead and run some data validation tests right away to start assessing and documenting the quality of our data. Since we are using a text dataset, we can use ValidMind's built-in array of text data quality tests to check that things like number of duplicates, missing values, and other common text data issues are not present in our dataset. We can also run some tests to check the sentiment and toxicity of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc4__'></a>\n",
    "\n",
    "## ValidMind objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_raw_ds = vm.init_dataset(\n",
    "    dataset=raw_df, input_id=\"raw_dataset\", target_column=\"cust_ipid_nm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5__'></a>\n",
    "\n",
    "## Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm.tests.list_tests(filter=\"data_validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_1__'></a>\n",
    "\n",
    "### Dataset summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_ds_summary = vm.init_dataset(\n",
    "    dataset=raw_df.drop(\"bal_date\", axis=1),\n",
    "    input_id=\"raw_dataset\",\n",
    "    target_column=\"cust_ipid_nm\",\n",
    ")\n",
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.DatasetDescription\", dataset=vm_ds_summary\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_2__'></a>\n",
    "\n",
    "### Duplicates\n",
    "\n",
    "First, let's check for duplicates in our dataset. We can use the `validmind.data_validation.Duplicates` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.Duplicates\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_3__'></a>\n",
    "\n",
    "### Missing values\n",
    "\n",
    "Next, let's check for missing values in our dataset. We can use the `validmind.data_validation.MissingValues` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\"validmind.data_validation.MissingValues\", dataset=vm_raw_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_4__'></a>\n",
    "\n",
    "### Unique rows\n",
    "\n",
    "Next, let's check for unique rows in our dataset. We can use the `validmind.data_validation.UniqueRows` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\"validmind.data_validation.UniqueRows\", dataset=vm_raw_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_5__'></a>\n",
    "\n",
    "### High cardinality\n",
    "\n",
    "Next, let's check for high cardinality in our dataset. We can use the `validmind.data_validation.HighCardinality` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighCardinality\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_6__'></a>\n",
    "\n",
    "### Skewness\n",
    "\n",
    "Next, let's check for skewness in our dataset. We can use the `validmind.data_validation.Skewness` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.Skewness\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_7__'></a>\n",
    "\n",
    "### Zero Values\n",
    "\n",
    "Next, let's check for zeros values in our dataset. We can use the `validmind.data_validation.TooManyZeroValues` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.TooManyZeroValues\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_8__'></a>\n",
    "\n",
    "### Descriptive statistics\n",
    "\n",
    "Next, let's check statistics of our dataset. We can use the `validmind.data_validation.DescriptiveStatistics` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.DescriptiveStatistics\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_9__'></a>\n",
    "\n",
    "### High pearson correlation\n",
    "\n",
    "Next, let's check person correlation of our dataset. We can use the `validmind.data_validation.HighPearsonCorrelation` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.HighPearsonCorrelation\", dataset=vm_raw_ds\n",
    ")\n",
    "result.log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc5_10__'></a>\n",
    "\n",
    "### Pearson correlation matrix\n",
    "\n",
    "Next, let's check person correlation matrix of our dataset. We can use the `validmind.data_validation.PearsonCorrelationMatrix` test and pass our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.data_validation.PearsonCorrelationMatrix\", dataset=vm_raw_ds\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6__'></a>\n",
    "\n",
    "## Segmentation of clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = raw_df.drop(\n",
    "    columns=[\n",
    "        \"LOB_data\",\n",
    "        \"cust_id\",\n",
    "        \"bal_date\",\n",
    "        \"ult_parent_cust_ipid_no\",\n",
    "        \"ult_parent_cust_nm\",\n",
    "        \"client\",\n",
    "        \"subclient\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "target_column = \"cust_ipid_nm\"\n",
    "cluster_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_1__'></a>\n",
    "\n",
    "### Clustering\n",
    "Let's build Kmeans model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.cluster import digits as demo_dataset\n",
    "\n",
    "cluster_df = cluster_df.dropna()\n",
    "train_df, validation_df, test_df = demo_dataset.preprocess(cluster_df)\n",
    "\n",
    "x_train = train_df.drop(target_column, axis=1)\n",
    "y_train = train_df[target_column]\n",
    "x_val = validation_df.drop(target_column, axis=1)\n",
    "y_val = validation_df[target_column]\n",
    "x_test = test_df.drop(target_column, axis=1)\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "\n",
    "x_train = pd.concat([x_train, x_val], axis=0)\n",
    "y_train = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "scale = False\n",
    "if scale:\n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_val = scaler.fit_transform(x_val)\n",
    "    x_test = scaler.fit_transform(x_test)\n",
    "\n",
    "\n",
    "n_clusters = 4\n",
    "model = KMeans(init=\"k-means++\", n_clusters=n_clusters, n_init=4)  # random_state=0\n",
    "model = model.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepate VM dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds = vm.init_dataset(\n",
    "    dataset=train_df, target_column=target_column, input_id=\"training_seg_dataset\"\n",
    ")\n",
    "\n",
    "vm_test_ds = vm.init_dataset(\n",
    "    dataset=test_df, target_column=target_column, input_id=\"test_seg_dataset\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_model = vm.init_model(model, input_id=\"kmean_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_2__'></a>\n",
    "\n",
    "### Prediction\n",
    "Prediction values can be attached using `assign_prediction` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_train_ds.assign_predictions(model=vm_model)\n",
    "vm_test_ds.assign_predictions(model=vm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_3__'></a>\n",
    "\n",
    "### Compare Manual vs predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix:training\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_4__'></a>\n",
    "\n",
    "### Confusion matrix - test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ConfusionMatrix:test\",\n",
    "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_5__'></a>\n",
    "\n",
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.HyperParametersTuning\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    "    params={\"param_grid\": {\"n_clusters\": range(3, 6)}},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_6__'></a>\n",
    "\n",
    "### Cluster performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.ClusterPerformanceMetrics\",\n",
    "    inputs={\"datasets\": (vm_train_ds, vm_test_ds), \"model\": vm_model},\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc6_7__'></a>\n",
    "\n",
    "### No of clusters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vm.tests.run_test(\n",
    "    \"validmind.model_validation.sklearn.KMeansClustersOptimization\",\n",
    "    inputs={\"dataset\": vm_train_ds, \"model\": vm_model},\n",
    "    params={\n",
    "        \"n_clusters\": range(2, 8),\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7__'></a>\n",
    "\n",
    "## Operational deposit  model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_1__'></a>\n",
    "\n",
    "### Operational deposit model compuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operational_deposit_df = raw_df.copy()\n",
    "target_column = \"cust_ipid_nm\"\n",
    "\n",
    "\n",
    "# Eod_outflow_ratio\n",
    "# Step 4: Statistical Analysis\n",
    "def calculate_eod_outflow_ratio(df):\n",
    "    df[\"eod_outflow_ratio\"] = df[\"EOD\"] / df[\"Total_Outflow\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "operational_deposit_df = calculate_eod_outflow_ratio(operational_deposit_df)\n",
    "\n",
    "\n",
    "# Step 5: Model Implementation\n",
    "def rolling_average(df, window=30):\n",
    "    df[\"rolling_eod_balance\"] = (\n",
    "        df.groupby(\"cust_ipid_nm\")[\"EOD\"]\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    df[\"rolling_daily_outflow\"] = (\n",
    "        df.groupby(\"cust_ipid_nm\")[\"Total_Outflow\"]\n",
    "        .rolling(window=window)\n",
    "        .mean()\n",
    "        .reset_index(level=0, drop=True)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "operational_deposit_df = rolling_average(operational_deposit_df)\n",
    "\n",
    "# # Step 6: Output Generation\n",
    "# def generate_outputs(df):\n",
    "#     output_df = df.groupby(['cust_ipid_nm', 'subclient']).agg({\n",
    "#         'rolling_eod_balance': 'last',\n",
    "#         'rolling_daily_outflow': 'last'\n",
    "#     }).reset_index()\n",
    "#     output_df['operational_core'] = output_df['rolling_eod_balance'] / output_df['rolling_daily_outflow']\n",
    "#     return output_df\n",
    "\n",
    "# raw_df = generate_outputs(raw_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_2__'></a>\n",
    "\n",
    "### Prepare VM dataset for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.datasets.cluster import digits as demo_dataset\n",
    "\n",
    "operational_deposit_df = operational_deposit_df.dropna()\n",
    "\n",
    "x_train = operational_deposit_df.drop(target_column, axis=1)\n",
    "y_train = operational_deposit_df[target_column]\n",
    "\n",
    "vm_od_ds = vm.init_dataset(\n",
    "    dataset=operational_deposit_df, input_id=\"od_dataset\", target_column=\"cust_ipid_nm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_3__'></a>\n",
    "\n",
    "### VM model\n",
    "VM provides flexibility to generate model as per the use case requirement. Here, it's simple we treat prediction value as value of column `rolling_daily_outflow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def operational_deposit(input):\n",
    "\n",
    "    return input[\"rolling_daily_outflow\"]\n",
    "\n",
    "\n",
    "vm_od_model = vm.init_model(\n",
    "    input_id=\"operational_deposit\", predict_fn=operational_deposit\n",
    ")\n",
    "vm_od_ds.assign_predictions(\n",
    "    model=vm_od_model, prediction_column=\"rolling_daily_outflow\"\n",
    ")\n",
    "print(vm_od_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_4__'></a>\n",
    "\n",
    "### External test provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import LocalTestProvider\n",
    "\n",
    "tests_folder = \"tests\"\n",
    "# initialize the test provider with the tests folder we created earlier\n",
    "my_test_provider = LocalTestProvider(tests_folder)\n",
    "\n",
    "vm.tests.register_test_provider(\n",
    "    namespace=\"demo_test_provider\",\n",
    "    test_provider=my_test_provider,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc7_5__'></a>\n",
    "\n",
    "### Simple custom test\n",
    "Let's plot timeseries line plot by grouping a specific column in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"demo_test_provider.TimeseriesGroupbyPlot\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"cust_ipid_nm\",\n",
    "        \"y_column\": \"Total_Outflow\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:Total_Outflow\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"client\",\n",
    "        \"y_column\": \"Total_Outflow\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:eod_outflow_ratio\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"subclient\",\n",
    "        \"y_column\": \"eod_outflow_ratio\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from validmind.tests import run_test\n",
    "\n",
    "result = run_test(\n",
    "    \"my_test_provider.TimeseriesGroupbyPlot:rolling_eod_balance\",\n",
    "    inputs={\"dataset\": vm_od_ds, \"model\": vm_od_model},\n",
    "    params={\n",
    "        \"date_column\": \"bal_date\",\n",
    "        \"groupby_column\": \"subclient\",\n",
    "        \"y_column\": \"rolling_eod_balance\",\n",
    "    },\n",
    ").log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc8__'></a>\n",
    "\n",
    "## Where to go from here\n",
    "\n",
    "In this notebook you have learned the end-to-end process to document a model with the ValidMind Library, running through some very common scenarios in a typical model development setting:\n",
    "\n",
    "- Running out-of-the-box tests\n",
    "- Documenting your model by adding evidence to model documentation\n",
    "- Extending the capabilities of the ValidMind Library by implementing custom tests\n",
    "- Ensuring that the documentation is complete by running all tests in the documentation template\n",
    "\n",
    "As a next step, you can explore the following notebooks to get a deeper understanding on how the ValidMind Library allows you generate model documentation for any use case:\n",
    "\n",
    "<a id='toc8_1__'></a>\n",
    "\n",
    "### Use cases\n",
    "\n",
    "- [Application scorecard demo](../code_samples/credit_risk/application_scorecard_demo.ipynb)\n",
    "- [Linear regression documentation demo](../code_samples/regression/quickstart_regression_full_suite.ipynb)\n",
    "- [LLM model documentation demo](../code_samples/nlp_and_llm/foundation_models_integration_demo.ipynb)\n",
    "\n",
    "<a id='toc8_2__'></a>\n",
    "\n",
    "### More how-to guides and code samples\n",
    "\n",
    "- [Explore available tests in detail](../how_to/explore_tests.ipynb)\n",
    "- [In-depth guide for implementing custom tests](../code_samples/custom_tests/implement_custom_tests.ipynb)\n",
    "- [In-depth guide to external test providers](../code_samples/custom_tests/integrate_external_test_providers.ipynb)\n",
    "- [Configuring dataset features](../how_to/configure_dataset_features.ipynb)\n",
    "- [Introduction to unit and composite metrics](../how_to/run_unit_metrics.ipynb)\n",
    "\n",
    "<a id='toc8_3__'></a>\n",
    "\n",
    "### Discover more learning resources\n",
    "\n",
    "All notebook samples can be found in the following directories of the ValidMind Library GitHub repository:\n",
    "\n",
    "- [Code samples](https://github.com/validmind/validmind-library/tree/main/notebooks/code_samples)\n",
    "- [How-to guides](https://github.com/validmind/validmind-library/tree/main/notebooks/how_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='toc9__'></a>\n",
    "\n",
    "## Upgrade ValidMind\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"background-color: #B5B5B510; color: black; border: 1px solid #083E44; border-left-width: 5px; box-shadow: 2px 2px 4px rgba(0, 0, 0, 0.2);border-radius: 5px;\">After installing ValidMind, youâ€™ll want to periodically make sure you are on the latest version to access any new features and other enhancements.</div>\n",
    "\n",
    "Retrieve the information for the currently installed version of ValidMind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip show validmind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the version returned is lower than the version indicated in our [production open-source code](https://github.com/validmind/validmind-library/blob/prod/validmind/__version__.py), restart your notebook and run:\n",
    "\n",
    "```bash\n",
    "%pip install --upgrade validmind\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to restart your kernel after running the upgrade package for changes to be applied."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
