{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Understanding and Utilizing RawData in ValidMind Tests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In ValidMind, test functions can return a special object called **RawData**. This object holds, as the name suggests, intermediate or unprocessed data that is produced somewhere in the test logic but is not returned as part of the test's visible output (tables or figures). This data can be useful when running post-processing functions with tests to recompute tabular outputs, redraw figure or even create new outputs entirely. In this notebook, we demonstrate how to access, inspect, and utilize RawData from ValidMind tests with a couple of examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import validmind as vm\n",
        "from validmind.datasets.classification import customer_churn\n",
        "\n",
        "raw_df = customer_churn.load_data()\n",
        "\n",
        "train_df, validation_df, test_df = customer_churn.preprocess(raw_df)\n",
        "\n",
        "x_train = train_df.drop(customer_churn.target_column, axis=1)\n",
        "y_train = train_df[customer_churn.target_column]\n",
        "x_val = validation_df.drop(customer_churn.target_column, axis=1)\n",
        "y_val = validation_df[customer_churn.target_column]\n",
        "\n",
        "model = xgb.XGBClassifier(early_stopping_rounds=10)\n",
        "model.set_params(\n",
        "    eval_metric=[\"error\", \"logloss\", \"auc\"],\n",
        ")\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    eval_set=[(x_val, y_val)],\n",
        "    verbose=False,\n",
        ")\n",
        "\n",
        "vm_raw_dataset = vm.init_dataset(\n",
        "    dataset=raw_df,\n",
        "    input_id=\"raw_dataset\",\n",
        "    target_column=customer_churn.target_column,\n",
        "    class_labels=customer_churn.class_labels,\n",
        "    __log=False,\n",
        ")\n",
        "\n",
        "vm_train_ds = vm.init_dataset(\n",
        "    dataset=train_df,\n",
        "    input_id=\"train_dataset\",\n",
        "    target_column=customer_churn.target_column,\n",
        "    __log=False,\n",
        ")\n",
        "\n",
        "vm_test_ds = vm.init_dataset(\n",
        "    dataset=test_df,\n",
        "    input_id=\"test_dataset\",\n",
        "    target_column=customer_churn.target_column,\n",
        "    __log=False,\n",
        ")\n",
        "\n",
        "vm_model = vm.init_model(\n",
        "    model,\n",
        "    input_id=\"model\",\n",
        "    __log=False,\n",
        ")\n",
        "\n",
        "vm_train_ds.assign_predictions(\n",
        "    model=vm_model,\n",
        ")\n",
        "\n",
        "vm_test_ds.assign_predictions(\n",
        "    model=vm_model,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 1: Using RawData from the ROC Curve Test\n",
        "\n",
        "In this example, we run the ROC Curve test, inspect its RawData output, and then create a custom ROC curve using the raw data values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from validmind.tests import run_test\n",
        "\n",
        "# Run the ROC Curve test normally\n",
        "result_roc = run_test(\n",
        "    \"validmind.model_validation.sklearn.ROCCurve\",\n",
        "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
        "    generate_description=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's assume we want to create a custom version of the above figure. First, let's inspect the raw data that this test produces so we can see what we have to work with.\n",
        "\n",
        "`RawData` objects have a `inspect()` method that will pretty print the attributes of the object to be able to quickly see the data and its types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect the RawData output from the ROC test\n",
        "print(\"RawData from ROC Curve Test:\")\n",
        "result_roc.raw_data.inspect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, the ROC Curve returns a `RawData` object with the following attributes:\n",
        "- `fpr`: A list of false positive rates\n",
        "- `tpr`: A list of true positive rates\n",
        "- `auc`: The area under the curve\n",
        "\n",
        "This should be enough to create our own custom ROC curve via a post-processing function without having to create a whole new test from scratch and without having to recompute any of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from validmind.vm_models.result import TestResult\n",
        "\n",
        "\n",
        "def custom_roc_curve(result: TestResult):\n",
        "    # Extract raw data from the test result\n",
        "    fpr = result.raw_data.fpr\n",
        "    tpr = result.raw_data.tpr\n",
        "    auc = result.raw_data.auc\n",
        "\n",
        "    # Create a custom ROC curve plot\n",
        "    fig = plt.figure()\n",
        "    plt.plot(fpr, tpr, label=f\"Custom ROC (AUC = {auc:.2f})\", color=\"blue\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random Guess\")\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"Custom ROC Curve from RawData\")\n",
        "    plt.legend()\n",
        "\n",
        "    # close the plot to avoid it automatically being shown in the notebook\n",
        "    plt.close()\n",
        "\n",
        "    # remove existing figure\n",
        "    result.remove_figure(0)\n",
        "\n",
        "    # add new figure\n",
        "    result.add_figure(fig)\n",
        "\n",
        "    return result\n",
        "\n",
        "# test it on the existing result\n",
        "modified_result = custom_roc_curve(result_roc)\n",
        "\n",
        "# show the modified result\n",
        "modified_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have created a post-processing function and verified that it works on our existing test result, we can use it directly in `run_test()` from now on:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "result = run_test(\n",
        "    \"validmind.model_validation.sklearn.ROCCurve\",\n",
        "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
        "    post_process_fn=custom_roc_curve,\n",
        "    generate_description=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## More Examples\n",
        "\n",
        "### Pearson Correlation Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try commenting out the `post_process_fn` argument in the following cell and see what happens between different runs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "def custom_heatmap(result: TestResult):\n",
        "    corr_matrix = result.raw_data.correlation_matrix\n",
        "\n",
        "    heatmap = go.Heatmap(\n",
        "        z=corr_matrix.values,\n",
        "        x=list(corr_matrix.columns),\n",
        "        y=list(corr_matrix.index),\n",
        "        colorscale=\"Viridis\",\n",
        "    )\n",
        "    fig = go.Figure(data=[heatmap])\n",
        "    fig.update_layout(title=\"Custom Heatmap from RawData\")\n",
        "\n",
        "    plt.close()\n",
        "\n",
        "    result.remove_figure(0)\n",
        "    result.add_figure(fig)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "result_corr = run_test(\n",
        "    \"validmind.data_validation.PearsonCorrelationMatrix\",\n",
        "    inputs={\"dataset\": vm_test_ds},\n",
        "    generate_description=False,\n",
        "    post_process_fn=custom_heatmap,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Precision-Recall Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try the same thing with the Precision-Recall Curve test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_pr_curve(result: TestResult):\n",
        "    precision = result.raw_data.precision\n",
        "    recall = result.raw_data.recall\n",
        "\n",
        "    fig = plt.figure()\n",
        "    plt.plot(recall, precision, label=\"Precision-Recall Curve\")\n",
        "    plt.xlabel(\"Recall\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title(\"Custom Precision-Recall Curve from RawData\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.close()\n",
        "    result.remove_figure(0)\n",
        "    result.add_figure(fig)\n",
        "\n",
        "    return result\n",
        "\n",
        "result_pr = run_test(\n",
        "    \"validmind.model_validation.sklearn.PrecisionRecallCurve\",\n",
        "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
        "    generate_description=False,\n",
        "    post_process_fn=custom_pr_curve,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Using RawData in Custom Tests\n",
        "\n",
        "These examples demonstrate some very simple ways to use the `RawData` feature of ValidMind tests. The majority of ValidMind-developed tests return some form of raw data that can be used to customize the output of the test. But you can also create your own tests that return `RawData` objects and use them in the same way.\n",
        "\n",
        "Let's take a look at how this can be done in custom tests."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from validmind import test, RawData\n",
        "from validmind.vm_models import VMDataset, VMModel\n",
        "\n",
        "\n",
        "@test(\"custom.MyCustomTest\")\n",
        "def MyCustomTest(dataset: VMDataset, model: VMModel) -> tuple[go.Figure, RawData]:\n",
        "    \"\"\"Custom test that produces a figure and a RawData object\"\"\"\n",
        "    # pretend we are using the dataset and model to compute some data\n",
        "    # ...\n",
        "\n",
        "    # create some fake data that will be used to generate a figure\n",
        "    data = pd.DataFrame({\"x\": [10, 20, 30, 40, 50], \"y\": [10, 20, 30, 40, 50]})\n",
        "\n",
        "    # create the figure (scatter plot)\n",
        "    fig = go.Figure(data=go.Scatter(x=data[\"x\"], y=data[\"y\"]))\n",
        "\n",
        "    # now let's create a RawData object that holds the \"computed\" data\n",
        "    raw_data = RawData(scatter_data_df=data)\n",
        "\n",
        "    # finally, return both the figure and the raw data\n",
        "    return fig, raw_data\n",
        "\n",
        "\n",
        "my_result = run_test(\n",
        "    \"custom.MyCustomTest\",\n",
        "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
        "    generate_description=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that the test result shows the figure. But since we returned a `RawData` object, we can also inspect the contents and see how we could use it to customize or regenerate the figure in the post-processing function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_result.raw_data.inspect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that we get a nicely-formatted preview of the dataframe we stored in the raw data object. Let's go ahead and use it to re-plot our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def custom_plot(result: TestResult):\n",
        "    data = result.raw_data.scatter_data_df\n",
        "\n",
        "    # use something other than a scatter plot\n",
        "    fig = go.Figure(data=go.Bar(x=data[\"x\"], y=data[\"y\"]))\n",
        "    fig.update_layout(title=\"Custom Bar Chart from RawData\")\n",
        "    fig.update_xaxes(title=\"X Axis\")\n",
        "    fig.update_yaxes(title=\"Y Axis\")\n",
        "\n",
        "    result.remove_figure(0)\n",
        "    result.add_figure(fig)\n",
        "\n",
        "    return result\n",
        "\n",
        "result = run_test(\n",
        "    \"custom.MyCustomTest\",\n",
        "    inputs={\"dataset\": vm_test_ds, \"model\": vm_model},\n",
        "    post_process_fn=custom_plot,\n",
        "    generate_description=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook has demonstrated how to use the `RawData` feature of ValidMind tests to customize the output of tests. It has also shown how to create custom tests that return `RawData` objects and use them in the same way.\n",
        "\n",
        "This feature is a powerful tool for creating custom tests and post-processing functions that can be used to generate a wide variety of outputs from ValidMind tests."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
