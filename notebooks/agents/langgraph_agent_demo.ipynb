{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LangGraph Agent Model Documentation\n",
        "\n",
        "This notebook demonstrates how to build sophisticated agents using LangGraph with:\n",
        "- Multiple tools and conditional routing\n",
        "- State management and memory\n",
        "- Error handling and validation\n",
        "- Integration with ValidMind for testing and monitoring\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Annotated, Sequence, Optional, Dict, Any\n",
        "from langchain.tools import tool\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END, START\n",
        "from langgraph.prebuilt import ToolNode\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph.message import add_messages\n",
        "import json\n",
        "\n",
        "# Load environment variables if using .env file\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    load_dotenv()\n",
        "except ImportError:\n",
        "    print(\"dotenv not installed. Make sure OPENAI_API_KEY is set in your environment.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import validmind as vm\n",
        "\n",
        "vm.init(\n",
        "    api_host=\"...\",\n",
        "    api_key=\"...\",\n",
        "    api_secret=\"...\",\n",
        "    model=\"...\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## LLM-Powered Tool Selection Router\n",
        "\n",
        "This section demonstrates how to create an intelligent router that uses an LLM to select the most appropriate tool based on user input and tool docstrings.\n",
        "\n",
        "### Benefits of LLM-Based Tool Selection:\n",
        "- **Intelligent Routing**: Understanding of natural language intent\n",
        "- **Dynamic Selection**: Can handle complex, multi-step requests  \n",
        "- **Context Awareness**: Considers conversation history and context\n",
        "- **Flexible Matching**: Not limited to keyword patterns\n",
        "- **Tool Documentation**: Uses actual tool docstrings for decision making\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enhanced Tools with Rich Docstrings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Advanced Calculator Tool\n",
        "@tool\n",
        "def advanced_calculator(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform mathematical calculations and solve arithmetic expressions.\n",
        "    \n",
        "    This tool can handle:\n",
        "    - Basic arithmetic: addition (+), subtraction (-), multiplication (*), division (/)\n",
        "    - Mathematical functions: sqrt, sin, cos, tan, log, exp\n",
        "    - Constants: pi, e\n",
        "    - Parentheses for order of operations\n",
        "    - Decimal numbers and scientific notation\n",
        "    \n",
        "    Args:\n",
        "        expression (str): Mathematical expression to evaluate (e.g., \"2 + 3 * 4\", \"sqrt(16)\", \"sin(pi/2)\")\n",
        "    \n",
        "    Returns:\n",
        "        str: Result of the calculation or error message\n",
        "        \n",
        "    Examples:\n",
        "        - \"Calculate 15 * 7 + 23\"\n",
        "        - \"What is the square root of 144?\"\n",
        "        - \"Solve 2^8\"\n",
        "        - \"What's 25% of 200?\"\n",
        "    \"\"\"\n",
        "    import math\n",
        "    import re\n",
        "    \n",
        "    try:\n",
        "        # Sanitize and evaluate safely\n",
        "        safe_expression = expression.replace('^', '**')  # Handle exponents\n",
        "        safe_expression = re.sub(r'[^0-9+\\-*/().,\\s]', '', safe_expression)\n",
        "        \n",
        "        # Add math functions\n",
        "        safe_dict = {\n",
        "            \"__builtins__\": {},\n",
        "            \"sqrt\": math.sqrt,\n",
        "            \"sin\": math.sin,\n",
        "            \"cos\": math.cos,\n",
        "            \"tan\": math.tan,\n",
        "            \"log\": math.log,\n",
        "            \"exp\": math.exp,\n",
        "            \"pi\": math.pi,\n",
        "            \"e\": math.e,\n",
        "        }\n",
        "        \n",
        "        result = eval(safe_expression, safe_dict)\n",
        "        return f\"The result is: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error calculating '{expression}': {str(e)}\"\n",
        "\n",
        "# Weather Service Tool\n",
        "@tool\n",
        "def weather_service(location: str, forecast_days: Optional[int] = 1) -> str:\n",
        "    \"\"\"\n",
        "    Get current weather conditions and forecasts for any city worldwide.\n",
        "    \n",
        "    This tool provides:\n",
        "    - Current temperature, humidity, and weather conditions\n",
        "    - Multi-day weather forecasts (up to 7 days)\n",
        "    - Weather alerts and warnings\n",
        "    - Historical weather data\n",
        "    - Seasonal weather patterns\n",
        "    \n",
        "    Args:\n",
        "        location (str): City name, coordinates, or location identifier\n",
        "        forecast_days (int, optional): Number of forecast days (1-7). Defaults to 1.\n",
        "    \n",
        "    Returns:\n",
        "        str: Weather information for the specified location\n",
        "        \n",
        "    Examples:\n",
        "        - \"What's the weather in Tokyo?\"\n",
        "        - \"Give me a 3-day forecast for London\"\n",
        "        - \"Is it going to rain in New York tomorrow?\"\n",
        "        - \"What's the temperature in Paris right now?\"\n",
        "    \"\"\"\n",
        "    import random\n",
        "    \n",
        "    conditions = [\"sunny\", \"cloudy\", \"partly cloudy\", \"rainy\", \"stormy\", \"snowy\"]\n",
        "    temp = random.randint(-10, 35)\n",
        "    condition = random.choice(conditions)\n",
        "    \n",
        "    forecast = f\"Weather in {location}:\\n\"\n",
        "    forecast += f\"Current: {condition}, {temp}Â°C\\n\"\n",
        "    \n",
        "    if forecast_days > 1:\n",
        "        forecast += f\"\\n{forecast_days}-day forecast:\\n\"\n",
        "        for day in range(1, forecast_days + 1):\n",
        "            day_temp = temp + random.randint(-5, 5)\n",
        "            day_condition = random.choice(conditions)\n",
        "            forecast += f\"Day {day}: {day_condition}, {day_temp}Â°C\\n\"\n",
        "    \n",
        "    return forecast\n",
        "\n",
        "# Document Search Engine Tool\n",
        "@tool\n",
        "def document_search_engine(query: str, document_type: Optional[str] = \"all\") -> str:\n",
        "    \"\"\"\n",
        "    Search through internal documents, policies, and knowledge base.\n",
        "    \n",
        "    This tool can search for:\n",
        "    - Company policies and procedures\n",
        "    - Technical documentation and manuals\n",
        "    - Compliance and regulatory documents\n",
        "    - Historical records and reports\n",
        "    - Product specifications and requirements\n",
        "    - Legal documents and contracts\n",
        "    \n",
        "    Args:\n",
        "        query (str): Search terms or questions about documents\n",
        "        document_type (str, optional): Type of document to search (\"policy\", \"technical\", \"legal\", \"all\")\n",
        "    \n",
        "    Returns:\n",
        "        str: Relevant document excerpts and references\n",
        "        \n",
        "    Examples:\n",
        "        - \"Find our data privacy policy\"\n",
        "        - \"Search for loan approval procedures\"\n",
        "        - \"What are the security guidelines for API access?\"\n",
        "        - \"Show me compliance requirements for financial reporting\"\n",
        "    \"\"\"\n",
        "    document_db = {\n",
        "        \"policy\": [\n",
        "            \"Data Privacy Policy: All personal data must be encrypted...\",\n",
        "            \"Remote Work Policy: Employees may work remotely up to 3 days...\",\n",
        "            \"Security Policy: All systems require multi-factor authentication...\"\n",
        "        ],\n",
        "        \"technical\": [\n",
        "            \"API Documentation: REST endpoints available at /api/v1/...\",\n",
        "            \"Database Schema: User table contains id, name, email...\",\n",
        "            \"Deployment Guide: Use Docker containers with Kubernetes...\"\n",
        "        ],\n",
        "        \"legal\": [\n",
        "            \"Terms of Service: By using this service, you agree to...\",\n",
        "            \"Privacy Notice: We collect information to provide services...\",\n",
        "            \"Compliance Framework: SOX requirements mandate quarterly audits...\"\n",
        "        ]\n",
        "    }\n",
        "    \n",
        "    results = []\n",
        "    search_types = [document_type] if document_type != \"all\" else document_db.keys()\n",
        "    \n",
        "    for doc_type in search_types:\n",
        "        if doc_type in document_db:\n",
        "            for doc in document_db[doc_type]:\n",
        "                if any(term.lower() in doc.lower() for term in query.split()):\n",
        "                    results.append(f\"[{doc_type.upper()}] {doc}\")\n",
        "    \n",
        "    if not results:\n",
        "        results.append(f\"No documents found matching '{query}'\")\n",
        "    \n",
        "    return \"\\n\\n\".join(results)\n",
        "\n",
        "# Smart Validator Tool\n",
        "@tool\n",
        "def smart_validator(input_data: str, validation_type: str = \"auto\") -> str:\n",
        "    \"\"\"\n",
        "    Validate and verify various types of data and inputs.\n",
        "    \n",
        "    This tool can validate:\n",
        "    - Email addresses (format, domain, deliverability)\n",
        "    - Phone numbers (format, country code, carrier info)\n",
        "    - URLs and web addresses\n",
        "    - Credit card numbers (format, type, checksum)\n",
        "    - Social security numbers and tax IDs\n",
        "    - Postal codes and addresses\n",
        "    - Date formats and ranges\n",
        "    - File formats and data integrity\n",
        "    \n",
        "    Args:\n",
        "        input_data (str): Data to validate\n",
        "        validation_type (str): Type of validation (\"email\", \"phone\", \"url\", \"auto\")\n",
        "    \n",
        "    Returns:\n",
        "        str: Validation results with detailed feedback\n",
        "        \n",
        "    Examples:\n",
        "        - \"Validate this email: user@example.com\"\n",
        "        - \"Is this a valid phone number: +1-555-123-4567?\"\n",
        "        - \"Check if this URL is valid: https://example.com\"\n",
        "        - \"Verify this credit card format: 4111-1111-1111-1111\"\n",
        "    \"\"\"\n",
        "    import re\n",
        "    \n",
        "    if validation_type == \"auto\":\n",
        "        # Auto-detect validation type\n",
        "        if \"@\" in input_data and \".\" in input_data:\n",
        "            validation_type = \"email\"\n",
        "        elif any(char.isdigit() for char in input_data) and any(char in \"+-() \" for char in input_data):\n",
        "            validation_type = \"phone\"\n",
        "        elif input_data.startswith((\"http://\", \"https://\", \"www.\")):\n",
        "            validation_type = \"url\"\n",
        "        else:\n",
        "            validation_type = \"general\"\n",
        "    \n",
        "    if validation_type == \"email\":\n",
        "        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
        "        is_valid = re.match(pattern, input_data) is not None\n",
        "        return f\"Email '{input_data}' is {'valid' if is_valid else 'invalid'}\"\n",
        "    \n",
        "    elif validation_type == \"phone\":\n",
        "        pattern = r'^\\+?1?[-.\\s]?\\(?[0-9]{3}\\)?[-.\\s]?[0-9]{3}[-.\\s]?[0-9]{4}$'\n",
        "        is_valid = re.match(pattern, input_data) is not None\n",
        "        return f\"Phone number '{input_data}' is {'valid' if is_valid else 'invalid'}\"\n",
        "    \n",
        "    elif validation_type == \"url\":\n",
        "        pattern = r'^https?://(?:[-\\w.])+(?:\\:[0-9]+)?(?:/(?:[\\w/_.])*(?:\\?(?:[\\w&=%.])*)?(?:\\#(?:[\\w.])*)?)?$'\n",
        "        is_valid = re.match(pattern, input_data) is not None\n",
        "        return f\"URL '{input_data}' is {'valid' if is_valid else 'invalid'}\"\n",
        "    \n",
        "    else:\n",
        "        return f\"Performed general validation on '{input_data}' - appears to be safe text input\"\n",
        "\n",
        "# Task Assistant Tool\n",
        "@tool\n",
        "def task_assistant(task_description: str, context: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    General-purpose task assistance and problem-solving tool.\n",
        "    \n",
        "    This tool can help with:\n",
        "    - Breaking down complex tasks into steps\n",
        "    - Providing guidance and recommendations\n",
        "    - Answering questions and explaining concepts\n",
        "    - Suggesting solutions to problems\n",
        "    - Planning and organizing activities\n",
        "    - Research and information gathering\n",
        "    \n",
        "    Args:\n",
        "        task_description (str): Description of the task or question\n",
        "        context (str, optional): Additional context or background information\n",
        "    \n",
        "    Returns:\n",
        "        str: Helpful guidance, steps, or information for the task\n",
        "        \n",
        "    Examples:\n",
        "        - \"How do I prepare for a job interview?\"\n",
        "        - \"What are the steps to deploy a web application?\"\n",
        "        - \"Help me plan a team meeting agenda\"\n",
        "        - \"Explain machine learning concepts for beginners\"\n",
        "    \"\"\"\n",
        "    responses = {\n",
        "        \"meeting\": \"For planning meetings: 1) Define objectives, 2) Create agenda, 3) Invite participants, 4) Prepare materials, 5) Set time limits\",\n",
        "        \"interview\": \"Interview preparation: 1) Research the company, 2) Practice common questions, 3) Prepare examples, 4) Plan your outfit, 5) Arrive early\",\n",
        "        \"deploy\": \"Deployment steps: 1) Test in staging, 2) Backup production, 3) Deploy code, 4) Run health checks, 5) Monitor performance\",\n",
        "        \"learning\": \"Learning approach: 1) Start with basics, 2) Practice regularly, 3) Build projects, 4) Join communities, 5) Stay updated\"\n",
        "    }\n",
        "    \n",
        "    task_lower = task_description.lower()\n",
        "    for key, response in responses.items():\n",
        "        if key in task_lower:\n",
        "            return f\"Task assistance for '{task_description}':\\n\\n{response}\"\n",
        "    \n",
        "    \n",
        "    return f\"\"\"For the task '{task_description}', I recommend: 1) Break it into smaller steps, 2) Gather necessary resources, 3)\n",
        "    Create a timeline, 4) Start with the most critical parts, 5) Review and adjust as needed.\n",
        "        \"\"\"\n",
        "\n",
        "# Collect all tools for the LLM router\n",
        "AVAILABLE_TOOLS = [\n",
        "    advanced_calculator,\n",
        "    weather_service, \n",
        "    document_search_engine,\n",
        "    smart_validator,\n",
        "    task_assistant\n",
        "]\n",
        "\n",
        "print(\"Enhanced tools with rich docstrings created!\")\n",
        "print(f\"Available tools: {len(AVAILABLE_TOOLS)}\")\n",
        "for tool in AVAILABLE_TOOLS:\n",
        "    print(f\"   - {tool.name}: {tool.description[:50]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tool Selection Router"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_llm_tool_router(available_tools: List, llm_model: str = \"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Create an intelligent router that uses LLM to select appropriate tools.\n",
        "    \n",
        "    Args:\n",
        "        available_tools: List of LangChain tools with docstrings\n",
        "        llm_model: LLM model to use for routing decisions\n",
        "        \n",
        "    Returns:\n",
        "        Function that routes user input to appropriate tools\n",
        "    \"\"\"\n",
        "    \n",
        "    # Initialize LLM for routing decisions\n",
        "    routing_llm = ChatOpenAI(model=llm_model, temperature=0.1)\n",
        "    \n",
        "    def generate_tool_descriptions(tools: List) -> str:\n",
        "        \"\"\"Generate formatted tool descriptions for the LLM.\"\"\"\n",
        "        descriptions = []\n",
        "        for tool in tools:\n",
        "            tool_info = {\n",
        "                \"name\": tool.name,\n",
        "                \"description\": tool.description,\n",
        "                \"args\": tool.args if hasattr(tool, 'args') else {},\n",
        "                \"examples\": []\n",
        "            }\n",
        "            \n",
        "                         # Extract examples from docstring if available\n",
        "            if hasattr(tool, 'func') and tool.func.__doc__:\n",
        "                docstring = tool.func.__doc__\n",
        "                if \"Examples:\" in docstring:\n",
        "                    examples_section = docstring.split(\"Examples:\")[1]\n",
        "                    examples = [line.strip().replace(\"- \", \"\") for line in examples_section.split(\"\\n\") \n",
        "                            if line.strip() and line.strip().startswith(\"-\")]\n",
        "                    tool_info[\"examples\"] = examples[:3]  # Limit to 3 examples\n",
        "        \n",
        "            descriptions.append(tool_info)\n",
        "        \n",
        "        return json.dumps(descriptions, indent=2)\n",
        "    \n",
        "    def intelligent_router(user_input: str, conversation_history: List = None) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Use LLM to intelligently select the most appropriate tool(s).\n",
        "        \n",
        "        Args:\n",
        "            user_input: User's request/question\n",
        "            conversation_history: Previous conversation context\n",
        "            \n",
        "        Returns:\n",
        "            Dict with routing decision and reasoning\n",
        "        \"\"\"\n",
        "        \n",
        "        # Generate tool descriptions\n",
        "        tool_descriptions = generate_tool_descriptions(available_tools)\n",
        "        \n",
        "                 # Build context from conversation history\n",
        "        context = \"\"\n",
        "        if conversation_history and len(conversation_history) > 0:\n",
        "            recent_messages = conversation_history[-4:]  # Last 4 messages for context\n",
        "            context = \"\\n\".join([f\"{msg.type}: {msg.content[:100]}...\" \n",
        "                                for msg in recent_messages if hasattr(msg, 'content')])\n",
        "        \n",
        "        # Create the routing prompt\n",
        "        routing_prompt = f\"\"\"You are an intelligent tool router. Your job is to analyze user requests and select the most appropriate tool(s) to handle them.\n",
        "\n",
        "            AVAILABLE TOOLS:\n",
        "            {tool_descriptions}\n",
        "\n",
        "            CONVERSATION CONTEXT:\n",
        "            {context if context else \"No previous context\"}\n",
        "\n",
        "            USER REQUEST: \"{user_input}\"\n",
        "\n",
        "            Analyze the user's request and determine:\n",
        "            1. Which tool(s) would best handle this request\n",
        "            2. If multiple tools are needed, what's the order?\n",
        "            3. What parameters should be passed to each tool?\n",
        "            4. If no tools are needed, should this go to general conversation?\n",
        "\n",
        "            Respond in this JSON format:\n",
        "            {{\n",
        "                \"routing_decision\": \"tool_required\" | \"general_conversation\" | \"help_request\",\n",
        "                \"selected_tools\": [\n",
        "                    {{\n",
        "                        \"tool_name\": \"tool_name\",\n",
        "                        \"confidence\": 0.95,\n",
        "                        \"parameters\": {{\"param\": \"value\"}},\n",
        "                        \"reasoning\": \"Why this tool was selected\"\n",
        "                    }}\n",
        "                ],\n",
        "                \"execution_order\": [\"tool1\", \"tool2\"],\n",
        "                \"overall_reasoning\": \"Overall analysis of the request\"\n",
        "            }}\n",
        "\n",
        "            IMPORTANT: Be precise with tool selection. Consider the tool descriptions and examples carefully.\"\"\"\n",
        "\n",
        "        try:\n",
        "            # Get LLM routing decision\n",
        "            response = routing_llm.invoke([\n",
        "                SystemMessage(content=\"You are a precise tool routing specialist. Always respond with valid JSON.\"),\n",
        "                HumanMessage(content=routing_prompt)\n",
        "            ])\n",
        "            \n",
        "            print(f\"Conversation history: {conversation_history}\")\n",
        "            print(f\"Routing response: {response}\")\n",
        "            # Parse the response\n",
        "            routing_result = json.loads(response.content)\n",
        "            print(f\"Routing result: {routing_result}\")\n",
        "\n",
        "            # Validate and enhance the result\n",
        "            validated_result = validate_routing_decision(routing_result, available_tools)\n",
        "            \n",
        "            return validated_result\n",
        "            \n",
        "        except json.JSONDecodeError as e:\n",
        "            # Fallback to simple routing if JSON parsing fails\n",
        "            return {\n",
        "                \"routing_decision\": \"general_conversation\",\n",
        "                \"selected_tools\": [],\n",
        "                \"execution_order\": [],\n",
        "                \"overall_reasoning\": f\"Failed to parse LLM response: {e}\",\n",
        "                \"fallback\": True\n",
        "            }\n",
        "        except Exception as e:\n",
        "            # General error fallback\n",
        "            return {\n",
        "                \"routing_decision\": \"general_conversation\", \n",
        "                \"selected_tools\": [],\n",
        "                \"execution_order\": [],\n",
        "                \"overall_reasoning\": f\"Router error: {e}\",\n",
        "                \"error\": True\n",
        "            }\n",
        "    \n",
        "    def validate_routing_decision(decision: Dict, tools: List) -> Dict:\n",
        "        \"\"\"Validate and enhance the routing decision.\"\"\"\n",
        "        \n",
        "        # Get available tool names\n",
        "        tool_names = [tool.name for tool in tools]\n",
        "        \n",
        "        # Validate selected tools exist\n",
        "        valid_tools = []\n",
        "        for tool_selection in decision.get(\"selected_tools\", []):\n",
        "            tool_name = tool_selection.get(\"tool_name\")\n",
        "            if tool_name in tool_names:\n",
        "                valid_tools.append(tool_selection)\n",
        "            else:\n",
        "                # Find closest match\n",
        "                from difflib import get_close_matches\n",
        "                matches = get_close_matches(tool_name, tool_names, n=1, cutoff=0.6)\n",
        "                if matches:\n",
        "                    tool_selection[\"tool_name\"] = matches[0]\n",
        "                    tool_selection[\"corrected\"] = True\n",
        "                    valid_tools.append(tool_selection)\n",
        "        \n",
        "        # Update the decision\n",
        "        decision[\"selected_tools\"] = valid_tools\n",
        "        decision[\"execution_order\"] = [tool[\"tool_name\"] for tool in valid_tools]\n",
        "        \n",
        "        # Add tool count\n",
        "        decision[\"tool_count\"] = len(valid_tools)\n",
        "        \n",
        "        return decision\n",
        "    \n",
        "    return intelligent_router\n",
        "\n",
        "# Create the intelligent router\n",
        "intelligent_tool_router = create_llm_tool_router(AVAILABLE_TOOLS)\n",
        "\n",
        "print(\"LLM-Powered Tool Router Created!\")\n",
        "print(\"Router Features:\")\n",
        "print(\"   - Uses LLM for intelligent tool selection\")\n",
        "print(\"   - Analyzes tool docstrings and examples\")\n",
        "print(\"   - Considers conversation context\")\n",
        "print(\"   - Provides confidence scores and reasoning\")\n",
        "print(\"   - Handles multi-tool requests\")\n",
        "print(\"   - Validates tool selections\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complete LangGraph Agent with Intelligent Router\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# Enhanced Agent State\n",
        "class IntelligentAgentState(TypedDict):\n",
        "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
        "    user_input: str\n",
        "    session_id: str\n",
        "    context: dict\n",
        "    routing_result: dict  # Store LLM routing decision\n",
        "    selected_tools: list\n",
        "    tool_results: dict\n",
        "\n",
        "def create_intelligent_langgraph_agent():\n",
        "    \"\"\"Create a LangGraph agent with LLM-powered tool selection.\"\"\"\n",
        "    \n",
        "    # Initialize the main LLM for responses\n",
        "    main_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7)\n",
        "    \n",
        "    # Bind tools to the main LLM\n",
        "    llm_with_tools = main_llm.bind_tools(AVAILABLE_TOOLS)\n",
        "    \n",
        "    def intelligent_router_node(state: IntelligentAgentState) -> IntelligentAgentState:\n",
        "        \"\"\"Router node that uses LLM to select appropriate tools.\"\"\"\n",
        "        \n",
        "        user_input = state[\"user_input\"]\n",
        "        messages = state.get(\"messages\", [])\n",
        "        \n",
        "        print(f\"Router analyzing: '{user_input}'\")\n",
        "        \n",
        "        # Use the intelligent router to analyze the request\n",
        "        routing_result = intelligent_tool_router(user_input, messages)\n",
        "        \n",
        "        print(f\"Routing decision: {routing_result['routing_decision']}\")\n",
        "        print(f\"Selected tools: {[tool['tool_name'] for tool in routing_result.get('selected_tools', [])]}\")\n",
        "        \n",
        "        # Store routing result in state\n",
        "        return {\n",
        "            **state,\n",
        "            \"routing_result\": routing_result,\n",
        "            \"selected_tools\": routing_result.get(\"selected_tools\", [])\n",
        "        }\n",
        "    \n",
        "    def llm_node(state: IntelligentAgentState) -> IntelligentAgentState:\n",
        "        \"\"\"Main LLM node that processes requests and decides on tool usage.\"\"\"\n",
        "        \n",
        "        messages = state[\"messages\"]\n",
        "        routing_result = state.get(\"routing_result\", {})\n",
        "        \n",
        "        # Create a system message based on routing analysis\n",
        "        system_context = f\"\"\"You are a helpful AI assistant with access to specialized tools.\n",
        "        ROUTING ANALYSIS:\n",
        "        - Decision: {routing_result.get('routing_decision', 'unknown')}\n",
        "        - Reasoning: {routing_result.get('overall_reasoning', 'No analysis available')}\n",
        "        - Selected Tools: {[tool['tool_name'] for tool in routing_result.get('selected_tools', [])]}\n",
        "        Based on the routing analysis, use the appropriate tools to help the user. If tools were recommended, use them. If not, respond conversationally.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Add system context to messages\n",
        "        enhanced_messages = [SystemMessage(content=system_context)] + list(messages)\n",
        "        \n",
        "        # Get LLM response\n",
        "        response = llm_with_tools.invoke(enhanced_messages)\n",
        "        \n",
        "        return {\n",
        "            **state,\n",
        "            \"messages\": messages + [response]\n",
        "        }\n",
        "    \n",
        "    def should_continue(state: IntelligentAgentState) -> str:\n",
        "        \"\"\"Decide whether to use tools or end the conversation.\"\"\"\n",
        "        last_message = state[\"messages\"][-1]\n",
        "        \n",
        "        # Check if the LLM wants to use tools\n",
        "        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
        "            return \"tools\"\n",
        "        \n",
        "        return END\n",
        "    \n",
        "    def help_node(state: IntelligentAgentState) -> IntelligentAgentState:\n",
        "        \"\"\"Provide help information about available capabilities.\"\"\"\n",
        "        \n",
        "        help_message = f\"\"\"ðŸ¤– **AI Assistant Capabilities**\n",
        "        \n",
        "            I'm an intelligent assistant with access to specialized tools. Here's what I can help you with:\n",
        "\n",
        "            ðŸ§® **Advanced Calculator** - Mathematical calculations and expressions\n",
        "            Examples: \"Calculate the square root of 144\", \"What's 25% of 200?\"\n",
        "\n",
        "            ðŸŒ¤ï¸ **Weather Service** - Current weather and forecasts worldwide  \n",
        "            Examples: \"Weather in Tokyo\", \"3-day forecast for London\"\n",
        "\n",
        "            ðŸ” **Document Search** - Find information in internal documents\n",
        "            Examples: \"Find privacy policy\", \"Search for API documentation\"\n",
        "\n",
        "            âœ… **Smart Validator** - Validate emails, phone numbers, URLs, etc.\n",
        "            Examples: \"Validate user@example.com\", \"Check this phone number\"\n",
        "\n",
        "            ðŸŽ¯ **Task Assistant** - General guidance and problem-solving\n",
        "            Examples: \"How to prepare for an interview\", \"Help plan a meeting\"\n",
        "\n",
        "            Just describe what you need in natural language, and I'll automatically select the right tools to help you!\"\"\"\n",
        "        \n",
        "        messages = state.get(\"messages\", [])\n",
        "        return {\n",
        "            **state,\n",
        "            \"messages\": messages + [AIMessage(content=help_message)]\n",
        "        }\n",
        "    \n",
        "    # Create the state graph\n",
        "    workflow = StateGraph(IntelligentAgentState)\n",
        "    \n",
        "    # Add nodes\n",
        "    workflow.add_node(\"router\", intelligent_router_node)\n",
        "    workflow.add_node(\"llm\", llm_node) \n",
        "    workflow.add_node(\"tools\", ToolNode(AVAILABLE_TOOLS))\n",
        "    workflow.add_node(\"help\", help_node)\n",
        "    \n",
        "    # Set entry point\n",
        "    workflow.add_edge(START, \"router\")\n",
        "    \n",
        "    # Conditional routing from router based on LLM analysis\n",
        "    def route_after_analysis(state: IntelligentAgentState) -> str:\n",
        "        \"\"\"Route based on the LLM's analysis.\"\"\"\n",
        "        routing_result = state.get(\"routing_result\", {})\n",
        "        decision = routing_result.get(\"routing_decision\", \"general_conversation\")\n",
        "        \n",
        "        if decision == \"help_request\":\n",
        "            return \"help\"\n",
        "        else:\n",
        "            return \"llm\"  # Let LLM handle both tool usage and general conversation\n",
        "    \n",
        "    workflow.add_conditional_edges(\n",
        "        \"router\",\n",
        "        route_after_analysis,\n",
        "        {\"help\": \"help\", \"llm\": \"llm\"}\n",
        "    )\n",
        "    \n",
        "    # From LLM, decide whether to use tools or end\n",
        "    workflow.add_conditional_edges(\n",
        "        \"llm\",\n",
        "        should_continue,\n",
        "        {\"tools\": \"tools\", END: END}\n",
        "    )\n",
        "    \n",
        "    # Tool execution flows back to LLM for final response\n",
        "    workflow.add_edge(\"tools\", \"llm\")\n",
        "    \n",
        "    # Help goes to end\n",
        "    workflow.add_edge(\"help\", END)\n",
        "    \n",
        "    # Set up memory\n",
        "    memory = MemorySaver()\n",
        "    \n",
        "    # Compile the graph\n",
        "    agent = workflow.compile(checkpointer=memory)\n",
        "    \n",
        "    return agent\n",
        "\n",
        "# Create the intelligent agent\n",
        "intelligent_agent = create_intelligent_langgraph_agent()\n",
        "\n",
        "print(\"Intelligent LangGraph Agent Created!\")\n",
        "print(\"Features:\")\n",
        "print(\"   - LLM-powered tool selection\")\n",
        "print(\"   - Analyzes tool docstrings and examples\")\n",
        "print(\"   - Context-aware routing decisions\")\n",
        "print(\"   - Automatic tool parameter extraction\")\n",
        "print(\"   - Confidence scoring and reasoning\")\n",
        "print(\"   - Fallback handling for edge cases\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ValidMind model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def agent_fn(input):\n",
        "    \"\"\"\n",
        "    Invoke the financial agent with the given input.\n",
        "    \"\"\"\n",
        "    initial_state = {\n",
        "    \"user_input\": input[\"input\"],\n",
        "    \"messages\": [HumanMessage(content=input[\"input\"])],\n",
        "    \"session_id\": input[\"session_id\"],\n",
        "    \"context\": {},\n",
        "    \"routing_result\": {},\n",
        "    \"selected_tools\": [],\n",
        "    \"tool_results\": {}\n",
        "}\n",
        "\n",
        "    session_config = {\"configurable\": {\"thread_id\": input[\"session_id\"]}}\n",
        "\n",
        "    result = intelligent_agent.invoke(initial_state, config=session_config)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "vm_intelligent_model = vm.init_agent(input_id=\"financial_model\", agent_fcn=agent_fn)\n",
        "# add model to the vm agent\n",
        "vm_intelligent_model.model = intelligent_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_intelligent_model.model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare sample  dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import uuid\n",
        "\n",
        "test_dataset = pd.DataFrame([\n",
        "    {\n",
        "        \"input\": \"Calculate the square root of 256 plus 15\",\n",
        "        \"expected_tools\": [\"advanced_calculator\"],\n",
        "        \"possible_outputs\": [271],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What's the weather like in Barcelona today?\", \n",
        "        \"expected_tools\": [\"weather_service\"],\n",
        "        \"possible_outputs\": [\"sunny\", \"rainy\", \"cloudy\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Find our company's data privacy policy\",\n",
        "        \"expected_tools\": [\"document_search_engine\"],\n",
        "        \"possible_outputs\": [\"privacy_policy.pdf\", \"data_protection.doc\", \"company_privacy_guidelines.txt\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Validate this email address: john.doe@company.com\",\n",
        "        \"expected_tools\": [\"smart_validator\"],\n",
        "        \"possible_outputs\": [\"valid\", \"invalid\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"How should I prepare for a technical interview?\",\n",
        "        \"expected_tools\": [\"task_assistant\"],\n",
        "        \"possible_outputs\": [\"algorithms\", \"data structures\", \"system design\", \"coding practice\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What's 25% of 480 and show me the weather in Tokyo\",\n",
        "        \"expected_tools\": [\"advanced_calculator\", \"weather_service\"],\n",
        "        \"possible_outputs\": [120, \"sunny\", \"rainy\", \"cloudy\", \"20Â°C\", \"68Â°F\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Help me understand machine learning basics\",\n",
        "        \"expected_tools\": [\"task_assistant\"],\n",
        "        \"possible_outputs\": [\"supervised\", \"unsupervised\", \"neural networks\", \"training\", \"testing\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"What can you do for me?\",\n",
        "        \"expected_tools\": [\"task_assistant\"],\n",
        "        \"possible_outputs\": [\"calculator\", \"weather\", \"email validator\", \"document search\", \"general assistance\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Calculate 5+3 and check the weather in Paris\",\n",
        "        \"expected_tools\": [\"advanced_calculator\", \"weather_service\"],\n",
        "        \"possible_outputs\": [8, \"sunny\", \"rainy\", \"cloudy\", \"22Â°C\", \"72Â°F\"],\n",
        "        \"session_id\": str(uuid.uuid4())\n",
        "    }\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initialize ValidMind dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_test_dataset = vm.init_dataset(\n",
        "    input_id=\"test_dataset\",\n",
        "    dataset=test_dataset,\n",
        "    target_column=\"possible_outputs\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run agent and assign predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_test_dataset.assign_predictions(vm_intelligent_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Dataframe display settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.set_option('display.max_colwidth', 40)\n",
        "pd.set_option('display.width', 120)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "vm_test_dataset._df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Agent prediction column adjustment in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "output = vm_test_dataset._df['financial_model_prediction']\n",
        "predictions = [row['messages'][-1].content for row in output]\n",
        "\n",
        "vm_test_dataset._df['output'] = output\n",
        "vm_test_dataset._df['financial_model_prediction'] = predictions\n",
        "vm_test_dataset._df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import langgraph\n",
        "\n",
        "@vm.test(\"my_custom_tests.LangGraphVisualization\")\n",
        "def LangGraphVisualization(model):\n",
        "    \"\"\"\n",
        "    Visualizes the LangGraph workflow structure using Mermaid diagrams.\n",
        "    \n",
        "    ### Purpose\n",
        "    Creates a visual representation of the LangGraph agent's workflow using Mermaid diagrams\n",
        "    to show the connections and flow between different components. This helps validate that\n",
        "    the agent's architecture is properly structured.\n",
        "    \n",
        "    ### Test Mechanism\n",
        "    1. Retrieves the graph representation from the model using get_graph()\n",
        "    2. Attempts to render it as a Mermaid diagram\n",
        "    3. Returns the visualization and validation results\n",
        "    \n",
        "    ### Signs of High Risk\n",
        "    - Failure to generate graph visualization indicates potential structural issues\n",
        "    - Missing or broken connections between components\n",
        "    - Invalid graph structure that cannot be rendered\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not hasattr(model, 'model') or not isinstance(model.model, langgraph.graph.state.CompiledStateGraph):\n",
        "            return {\n",
        "                'test_results': False,\n",
        "                'summary': {\n",
        "                    'status': 'FAIL', \n",
        "                    'details': 'Model must have a LangGraph Graph object as model attribute'\n",
        "                }\n",
        "            }\n",
        "        graph = model.model.get_graph(xray=False)\n",
        "        mermaid_png = graph.draw_mermaid_png()\n",
        "        return mermaid_png\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            'test_results': False, \n",
        "            'summary': {\n",
        "                'status': 'FAIL',\n",
        "                'details': f'Failed to generate graph visualization: {str(e)}'\n",
        "            }\n",
        "        }\n",
        "\n",
        "vm.tests.run_test(\n",
        "    \"my_custom_tests.LangGraphVisualization\",\n",
        "    inputs = {\n",
        "        \"model\": vm_intelligent_model\n",
        "    }\n",
        ").log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Accuracy Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import validmind as vm\n",
        "\n",
        "@vm.test(\"my_custom_tests.accuracy_test\")\n",
        "def accuracy_test(model, dataset, list_of_columns):\n",
        "    \"\"\"\n",
        "    Run tests on a dataset of questions and expected responses.\n",
        "    Optimized version using vectorized operations and list comprehension.\n",
        "    \"\"\"\n",
        "    df = dataset._df\n",
        "    \n",
        "    # Pre-compute responses for all tests\n",
        "    y_true = dataset.y.tolist()\n",
        "    y_pred = dataset.y_pred(model).tolist()\n",
        "\n",
        "    # Vectorized test results\n",
        "    test_results = []\n",
        "    for response, keywords in zip(y_pred, y_true):\n",
        "        test_results.append(any(str(keyword).lower() in str(response).lower() for keyword in keywords))\n",
        "        \n",
        "    results = pd.DataFrame()\n",
        "    column_names = [col + \"_details\" for col in list_of_columns]\n",
        "    results[column_names] = df[list_of_columns]\n",
        "    results[\"actual\"] = y_pred\n",
        "    results[\"expected\"] = y_true\n",
        "    results[\"passed\"] = test_results\n",
        "    results[\"error\"] = None if test_results else f'Response did not contain any expected keywords: {y_true}'\n",
        "    \n",
        "    return results\n",
        "   \n",
        "result = vm.tests.run_test(\n",
        "    \"my_custom_tests.accuracy_test\",\n",
        "    inputs={\n",
        "        \"dataset\": vm_test_dataset,\n",
        "        \"model\": vm_intelligent_model\n",
        "    },\n",
        "    params={\n",
        "        \"list_of_columns\": [\"input\"]\n",
        "    }\n",
        ")\n",
        "result.log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tool Call Accuracy Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import validmind as vm\n",
        "\n",
        "# Test with a real LangGraph result instead of creating mock objects\n",
        "@vm.test(\"my_custom_tests.tool_call_accuracy\")\n",
        "def tool_call_accuracy(dataset, agent_output_column, expected_tools_column):\n",
        "    \"\"\"Test validation using actual LangGraph agent results.\"\"\"\n",
        "    # Let's create a simpler validation without the complex RAGAS setup\n",
        "    def validate_tool_calls_simple(messages, expected_tools):\n",
        "        \"\"\"Simple validation of tool calls without RAGAS dependency issues.\"\"\"\n",
        "        \n",
        "        tool_calls_found = []\n",
        "        \n",
        "        for message in messages:\n",
        "            if hasattr(message, 'tool_calls') and message.tool_calls:\n",
        "                for tool_call in message.tool_calls:\n",
        "                    # Handle both dictionary and object formats\n",
        "                    if isinstance(tool_call, dict):\n",
        "                        tool_calls_found.append(tool_call['name'])\n",
        "                    else:\n",
        "                        # ToolCall object - use attribute access\n",
        "                        tool_calls_found.append(tool_call.name)\n",
        "        \n",
        "        # Check if expected tools were called\n",
        "        accuracy = 0.0\n",
        "        matches = 0\n",
        "        if expected_tools:\n",
        "            matches = sum(1 for tool in expected_tools if tool in tool_calls_found)\n",
        "            accuracy = matches / len(expected_tools)\n",
        "        \n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'expected_tools': expected_tools,\n",
        "            'found_tools': tool_calls_found,\n",
        "            'matches': matches,\n",
        "            'total_expected': len(expected_tools) if expected_tools else 0\n",
        "        }\n",
        "\n",
        "    df = dataset._df\n",
        "    \n",
        "    results = []\n",
        "    for i, row in df.iterrows():\n",
        "        result = validate_tool_calls_simple(row[agent_output_column]['messages'], row[expected_tools_column])\n",
        "        results.append(result)\n",
        "         \n",
        "    return results\n",
        "\n",
        "vm.tests.run_test(\n",
        "    \"my_custom_tests.tool_call_accuracy\",\n",
        "    inputs = {\n",
        "        \"dataset\": vm_test_dataset,\n",
        "    },\n",
        "    params = {\n",
        "        \"agent_output_column\": \"output\",\n",
        "        \"expected_tools_column\": \"expected_tools\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RAGAS Tests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset preparation - Extract Context from agent's stats "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils import capture_tool_output_messages, extract_tool_results_only, get_final_agent_response, format_tool_outputs_for_display\n",
        "\n",
        "tool_messages = []\n",
        "for i, row in vm_test_dataset._df.iterrows():\n",
        "    tool_message = \"\"\n",
        "    # Print messages in a readable format\n",
        "    result = row['output']\n",
        "    # Capture all tool outputs and metadata\n",
        "    captured_data = capture_tool_output_messages(result)\n",
        "\n",
        "    # Get just the tool results in a simple format\n",
        "    tool_results = extract_tool_results_only(result)\n",
        "\n",
        "    # Get the final agent response\n",
        "    final_response = get_final_agent_response(result)\n",
        "\n",
        "    # Print formatted summary\n",
        "    # print(format_tool_outputs_for_display(captured_data))\n",
        "\n",
        "    # Access specific tool outputs\n",
        "    for output in captured_data[\"tool_outputs\"]:\n",
        "        # print(f\"Tool: {output['tool_name']}\")\n",
        "        # print(f\"Output: {output['content']}\")\n",
        "        tool_message += output['content']\n",
        "        # print(\"-\" * 30)\n",
        "    tool_messages.append([tool_message])\n",
        "\n",
        "vm_test_dataset._df['tool_messages'] = tool_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm_test_dataset._df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Faithfulness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.tests.run_test(\n",
        "    \"validmind.model_validation.ragas.Faithfulness\",\n",
        "    inputs={\"dataset\": vm_test_dataset},\n",
        "    param_grid={\n",
        "        \"user_input_column\": [\"input\"],\n",
        "        \"response_column\": [\"financial_model_prediction\"],\n",
        "        \"retrieved_contexts_column\": [\"tool_messages\"],\n",
        "    },\n",
        ").log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Response Relevancy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.tests.run_test(\n",
        "    \"validmind.model_validation.ragas.ResponseRelevancy\",\n",
        "    inputs={\"dataset\": vm_test_dataset},\n",
        "    params={\n",
        "        \"user_input_column\": \"input\",\n",
        "        \"response_column\": \"financial_model_prediction\",\n",
        "        \"retrieved_contexts_column\": \"tool_messages\",\n",
        "    }\n",
        ").log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Context Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.tests.run_test(\n",
        "    \"validmind.model_validation.ragas.ContextRecall\",\n",
        "    inputs={\"dataset\": vm_test_dataset},\n",
        "    param_grid={\n",
        "        \"user_input_column\": [\"input\"],\n",
        "        \"retrieved_contexts_column\": [\"tool_messages\"],\n",
        "        \"reference_column\": [\"financial_model_prediction\"],\n",
        "    },\n",
        ").log()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AspectCritic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vm.tests.run_test(\n",
        "    \"validmind.model_validation.ragas.AspectCritic\",\n",
        "    inputs={\"dataset\": vm_test_dataset},\n",
        "    param_grid={\n",
        "        \"user_input_column\": [\"input\"],\n",
        "        \"response_column\": [\"financial_model_prediction\"],\n",
        "        \"retrieved_contexts_column\": [\"tool_messages\"],\n",
        "    },\n",
        ").log()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ValidMind Library",
      "language": "python",
      "name": "validmind"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
